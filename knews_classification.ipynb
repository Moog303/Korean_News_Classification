{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import konlpy\n",
    "import fasttext\n",
    "import re\n",
    "import h5py\n",
    "\n",
    "import sys, os \n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import MaxPooling1D, Embedding, Dense, Concatenate, Input, Reshape, Bidirectional, LSTM, Flatten, Dropout, Conv1D, Conv2D, MaxPooling2D, GRU, TimeDistributed\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = range(0,8)\n",
    "numTrain = range(0,160)\n",
    "numTest = range(160,200)\n",
    "\n",
    "def text_cleaner(text):\n",
    "    cleantext = []\n",
    "    publisher = \"\\((.*?)\\)\"\n",
    "    braces = \"\\[(.*?)\\]\"\n",
    "    braces2 = \"\\{(.*?)\\}\"\n",
    "    braces3 = \"\\【(.*?)\\】\"\n",
    "    writer = \"특파원\"\n",
    "    writer2 = \"기자\"\n",
    "    weird = \"[=_\\.,;:~…\\\"\\\"\\'\\'◇%\\<\\>/·○★☆]\"\n",
    "    tab = '\\\\t'\n",
    "    newline = '\\\\n'\n",
    "    for line in text:\n",
    "        clean = re.sub(writer, '', line)\n",
    "        clean = re.sub(writer2, '', clean)\n",
    "        clean = re.sub(publisher,'', clean)\n",
    "        clean = re.sub(braces,'', clean)\n",
    "        clean = re.sub(braces2,'', clean)\n",
    "        clean = re.sub(braces3,'', clean)\n",
    "        clean = re.sub('[YTN,OSEN]','', clean)\n",
    "        clean = re.sub(weird,'', clean)\n",
    "        clean = re.sub(tab,'', clean)\n",
    "        clean = re.sub(newline,'',clean)\n",
    "        cleantext.append(clean)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "Ytrain = []\n",
    "Xtest = []\n",
    "Ytest = []\n",
    "Xdata = []\n",
    "Ydata = []\n",
    "\n",
    "for n in range(0,200):\n",
    "    for c in category:\n",
    "        f = open('./newsData/{0}/{0}{1:03d}NewsData.txt'.format(c,n))\n",
    "        Xdata.append(f.read())\n",
    "        Ydata.append(c)\n",
    "        \n",
    "Ydata2 = list(Ydata)\n",
    "Xdata2 = list(Xdata)\n",
    "\n",
    "Xtrain = Xdata2[:1280]\n",
    "Xtest = Xdata2[1280:]\n",
    "Ytrain = Ydata2[:1280]\n",
    "Ytest = Ydata2[1280:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata = text_cleaner(Xdata)\n",
    "Xtrain = text_cleaner(Xtrain)\n",
    "Xtest = text_cleaner(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['동남아 담당 北 최희철 부상 베이징 도착싱가포르행 주목최 부상 행선지방문 목적 질문에는 묵묵부답 김진방   북한이 북미 정상회담 무산 가능성까지 거론하며 강경한 태도를 보이는 가운데 동남아시아 외교를 담당하는 최희철 북한 외무성 부상이 19일 중국 베이징 서우두 공항에 모습을 드러냈다최 부상은 이날 오전 평양발 고려항공 J151편을 이용해 베이징 서우두 공항에 도착했다최 부상은 최종 목적지를 묻는 취재진의 질문에 아무런 답변을 하지 않고 북한 대사관 관계자들과 함께 공항을 빠져나갔다북미 정상회담을 20여 일 앞둔 상황에서 동남아 외교통인 최 부상이 정상회담 준비 등을 위해 회담 개최 예정지인 싱가포르를 방문할 가능성도 제기되고 있다최 부상은 지난 3월에도 아세안 의장국이기도 한 싱가포르를 방문해 양국관계와 올해 8월 열리는 아세안지역안보포럼 의제 등을 논의한 바 있다또 지난해 북핵 문제를 두고 북미 간 긴장관계가 형성됐을 때도 ARF에 참석해 아세안을 상대로 여론전을 펼쳤다 북한의 초청으로 비자이 쿠마르 싱 인도 외교부 국무장관이 방북했을 때도 최 부상은 싱 국무장관을 직접 영접하고 한반도 문제를 논의하기도 했다베이징 소식통은 최 부상이 대미 외교담당이 아니기 때문에 싱가포르로 갈 가능성이 큰 것은 아니다며 만약 싱가포르에 간다면 정상회담과 관련한 지원 작업 준비 등을 위한 것일 가능성이 크다고 말했다', ' 한달 새 두 번이나 LG 연구단지에 간 대통령국민이 선출한 일국의 대통령이란 자리는 시쳇말로 어마무시합니다 행정의 수반이자 외교적으로는 국가를 대표하는 얼굴이고 대부분 군 통수권까지 갖고 있습니다막강한 권한만큼 국민적 관심도 집중됩니다 사소한 말 한마디와 행동은 물론 옷차림과 먹는 음식 심지어 순식간에 스쳐 가는 표정에도 의미가 담깁니다 설사 그런 의도가 전혀 없더라도 누군가는 거기서 ‘맥락’을 뽑아내기 위해 열심이죠문재인 대통령도 마찬가지입니다 대통령을 보좌하는 청와대의 수많은 수석과 비서관 등이 국정철학을 극대화하고 효과적인 메시지를 전달하기 위해 골몰합니다 한반도의 운명을 가를 중요한 회담들이 눈앞인 데다 댓글 조작을 일으킨 드루킹 특검법과 추가경정예산안을 두고 여야가 격돌하는 요즘 같을 때는 더욱 그럴 겁니다이런 분위기에서는 조그만 논란도 사전에 차단하기 위해 대통령의 동선 또한 더욱 치밀해질 텐데 채 한 달도 안 돼 문 대통령이 두 번이나 발길을 한 곳이 있습니다 LG가 서울 강서구 마곡동에 조성한 융복합 연구개발 단지 LG사이언스파크입니다첫 방문은 지난달 20일입니다 2014년 첫 삽을 뜬 LG사이언스파크는 3년 6개월 만에 완성됐고 이날 개장식이 열렸습니다 구본준 LG 부회장과 허창수 G 회장 등이 문 대통령을 맞이했습니다 문 대통령은 LG디스플레이가 개발한 두루마리형 디스플레이 LG전자의 인공지능 로봇과 미래형 계기판이 적용된 자동차 모형 등을 직접 체험했습니다 LG로서는 엄청난 홍보 효과를 얻었습니다대기업과는 썩 친하지 않은 문 대통령도 일찌감치 지주회사 체재를 완성한 LG는 좀 달랐던 것 같습니다 문 대통령은 축사 중 “대기업과 중소기업이 상생협력하고 창업이 활발히 이뤄질 수 있도록 동반성장의 모범이 돼달라”고 언급하기도 했습니다LG사이언스파크 두 번째 방문은 지난 17일입니다 날짜로 따지면 27일 만인데 그새 상황은 많이 달라졌습니다 검찰이 지난 9일 100억원대 양도소득세 탈루 혐의로 서울 여의도 LG트윈타워의 LG 본사를 전격 압수수색 했습니다 아직 수사가 진행 중이지만 ‘LG착한 기업’이란 등식에 흠이 생겼습니다문 대통령과 김정은 북한 국무위원장이 지난달 27일 판문점 평화의 집에서 정상회담을 가져 남북관계도 급진전했습니다 남북문제의 분수령에 서 있는 문 대통령이 한 달도 채 안 돼 같은 장소를 게다가 기업의 R&D 단지를 방문한 것은 이례적입니다 게다가 이번 주 문 대통령의 외부 공식 일정은 달랑 이거 하나였습니다 18일 광주에서 열린 제35주년 5ㆍ18 민주화운동기념식에도 이낙연 국무총리를 보내고 불참했습니다 22일 미국에서 열리는 한미정상회담 다음 달 12일 싱가포르에서 예정된 북미정상회담 준비에 전념하기 위해서인 것으로 알려졌습니다그런데도 굳이 LG사이언스파크에 간 이유는 ‘2018년 대한민국 혁신성장 보고대회’에 답이 있을 것 같습니다 이날은 지난해 연말 확정한 성장동력의 성과를 점검하고 세부 추진계획을 공유하는 자리였습니다 관계부처들이 논의를 거쳐 경기 성남시 판교테크노밸리와 LG사이언스파크 등 복수의 후보지를 추천했다고 알려졌습니다 장소를 확정한 것은 청와대일 겁니다 청와대 측은 출입들의 질문에 “실내에서 드론을 작동한 만한 장소로 적합했을 뿐 다른 의미는 없다”고 설명했다고 합니다문재인 정부 경제정책의 양대 축은 소득주도성장과 혁신성장입니다 최저임금 인상과 근로시간 단축 등 소득주도성장은 불과 1년 만에 빠른 속도로 진행되고 있지만 혁신성장은 더디기만 합니다 국민이 체감하는 수준도 그렇고 혁신성장이 성공적이라고 평가하는 경제 전문가도 보이지 않습니다 문 대통령은 이날 “무엇보다 중요한 것은 속도이고 국민이 성과를 체감해야 혁신성장 붐이 인다”고 강조했습니다재계에서는 일말의 기대감이 감지됩니다 역사적인 북미정상회담을 앞뒀지만 “먹고 사는 문제 역시 중요하다”는 대통령의 메시지로 해석되니까요 분배로 기울었던 경제의 무게중심이 성장 쪽으로 조금은 이동하지 않을까 생각한다면 뇌피셜일까요', '9급 공무원에 몰린 21만 명수험생 피말린 24시오늘 서울을 제외한 전국에서 9급 지방직 공무원 시험이 치러졌습니다 21만 명이 넘는 수험생이 몰렸는데요 응시생들의 어제와 오늘 이틀간의 모습을 배영진 가 취재했습니다  9급 지방직 공무원 시험 하루 전 수험생들은 숨죽이며 한 문제 한 문제 집중합니다 각자의 방식으로 총정리를 하며 결전의 의지를 다지는 얼굴들 숨소리조차 들리지 않습니다  이제 시험이 하루도 채 남지 않은 이 시간 수험생들은 한 문제로 당락이 결정될 수 있다는 생각에 오늘까지 외로운 싸움’을 이어가고 있습니다 결혼도 연애도 출산도 포기한 포 세대에게 마지막 ‘신의 직장’으로 불리는 지방직 9급 공무원 올해 선발 인원은 1만 4천 8백여 명입니다 지난해보다 4천 5백명 가까이 늘었지만 경쟁률은 142대 1을 기록했습니다  100문제를 100분 안에 정확하게 풀어내야 하므로 수험생들은 한 달 전부터 굉장히 긴장을 많이 합니다 이제 남은 건 컨디션 조절  평소에 체크를 해 놓거든요 색깔을 다르게 해서 마지막에 모를 때 모두 한꺼번에 볼 수 있게  마지막 날이라고 너무 책보고 앉아 있으면 잘 눈에 안 들어가서 좀 쉬는 편입니다 이제 결전의 날이 밝았고 이른 아침부터 수험생들이 몰려듭니다 국어 영어 한국사 등 5과목을 푸는 실전 100분 간의 적막함이 끝나고 홀가분한 표정으로 드디어 시험장을 나옵니다  떨렸는데 끝나서 기분이 시원하고 결과 나와봐야 알 거 같습니다 그러나 예상보다 어려웠던 문제가 마음에 걸립니다  기분은 별로 좋지 않아요 시원섭섭하지 않고 그냥 그런 거 같습니다 시험이 끝난 뒤에도 고사장에는 수험생들의 열기가 남아 있었습니다 채널A뉴스 배영진입니다', ' 다소 더운 월요일큰 일교차 감기 조심하세요 다소 더운 월요일큰 일교차 감기 조심하세요화창해서 나들이 하기 좋았던 휴일 마무리 잘하고 계신가요?징검다리 연휴 동안 특별한 계획 있으시다면 날씨로 인한 불편은 없겠습니다우선 내일은 하늘에 구름이 조금 끼겠지만 기온은 서울 24도로 오늘보다 따뜻하겠고요석가탄신일인 화요일에도 23도로 예년 이맘때 수준 보이겠습니다다만 하늘이 차츰 흐려져 밤에는 전국에서 비가 내리겠습니다내일 전국 하늘 대체로 맑다가 밤부터 구름이 많아지겠고요해안가를 중심으로는 바람이 강하게 불겠습니다시설물 피해 없도록 미리 점검하시고요내일 아침 강원 영동으로는 안개가 끼는 곳이 있어 출근길 교통안전에도 유의하시기 바랍니다내일 아침 기온 서울 12도 대구 13도 전주 11도로 오늘과 비슷하거나 조금 높겠고요내일 낮기온 서울 24도 춘천 26도 전주 25도로 대부분 25도 안팎을 보여 다소 덥겠지만 바닷바람이 불어오는 동해안 지역은 강릉 18도 등으로 내륙에 비해서 상대적으로 기온이 조금 낮겠습니다한편 동해와 남해상에는 풍랑특보가 내려져 있습니다물결도 최고 4m6m로 매우 높게 일 것으로 보여 항해나 조업시 각별히 조심하셔야겠습니다화요일 밤에 시작되는 비는 수요일 오전에는 모두 그치겠습니다이후로는 맑은 날씨 속에 기온도 26도로 웃돌아서 따뜻하겠는데요일교차는 계속해서 크게 벌어집니다건강 관리 잘해 주시기 바랍니다날씨 전해 드렸습니다', ' 화난 트럼프 북미회담 계속해야 하나 측근들 다그쳐트럼프 불편한 심기 보여주는 신호참모들 협상력 우려 이윤영   다음달 북미정상회담이 정치적 낭패가 될 수도 있다는 도널드 트럼프 대통령의 우려가 갈수록 커지면서 트럼프 대통령이 참모들을 압박하기 시작했다고 미국 유력신문인 뉴욕타임스 보도가 나왔다\\xa0역사적인 이번 북미회담을 진행하는 위험 부담을 계속 떠안고 가야 하는지에 대해 최근 며칠 간 참모들에게 질문을 퍼부었다는 것이다\\xa0는 20일 미 정부 및 외국 정부 관계자들을 인용해 이같은 백악관 내부 분위기를 전했다\\xa0에 따르면 트럼프 대통령은 일방적인 핵포기를 강요하면 북미정상회담을 재고려할 수 있다는 지난 16일 김계관 북한 외무성 제1부상의 담화 발표에 적잖이 놀란 것으로 전해졌다\\xa0이에 트럼프 대통령은 지난 17∼18일 참모들에게 회담을 계속해서 진행하는 것의 타당성에 관해 참모들에게 질문 공세를 했다\\xa0이어 19일 밤에는 문재인 대통령과 전화통화를 하고 북한의 공식 담화 내용이 문 대통령이 자신에게 전달해 온 내용과 왜 상충하는지 물었다 이날 통화는 문 대통령의 워싱턴 방문을 사흘 앞두고 이뤄진 것이다\\xa0이를 두고 미 정부 일각에서는 문 대통령이 워싱턴에 올 때까지 기다릴 수만은 없다는 트럼프 대통령의 불편한 심기를 보여주는 것이라는 해석이 나온다고\\xa0는 전했다\\xa0특히 참모들은 트럼프 대통령이 노벨상을 염두에 두면서 이번 회담을 지나치게 갈망하는 듯한 신호를 보인다는 점에 우려를 나타내고 있다\\xa0트럼프 대통령의 이러한 열망을 알아챈 김정은 북한 국무위원장이 비핵화 협상에서 시간이 지나면서 희미해질 약속을 할 수도 있다는 것이다\\xa0참모들이 우려하는 또 한 가지는 비핵화 협상에서 미국이 양보할 수 없는 핵심요소에 대해 트럼프 대통령이 과연 제대로 이해를 하고 있는 것인지 또 세부 협상 계획에서 트럼프 대통령이 어떤 카드를 가지고 있느냐에 대한 것이다\\xa0최근 두 차례 방북을 마치고 돌아온 마이크 폼페이오 국무부 장관은 김 위원장에 대해 복잡한 논의에도 아주 능할 정도로 영리하다는 평가를 내놓은 바 있다\\xa0하지만 트럼프 대통령은 전임 버락 오바마조지 부시 W 대통령과는 달리 우라늄 농축 능력이라든지 플루토늄 재처리 핵무기 생산 및 미사일 프로그램 등에 대한 세세한 브리핑을 듣는 것을 견디지 못한다는 게 참모들의 전언이다\\xa0미 정부 관계자들은 김 위원장이 이번 북미회담에서 향후 6개월 내에 핵무기 일부를 넘기고 관련 시설을 폐쇄하며 사찰을 허용하는 타임 테이블에 동의할 것으로 예상된다고 말해왔다\\xa0실제 지난 17일 일본 아사히신문은 미국이 사전협상에서 북한이 보유한 핵탄두와 핵 관련 물질 등 일부를 6개월 안에 해외로 반출할 것을 요구했다고 보도했다\\xa0하지만 이 같은 스케줄은 과거 북한의 전통적힌 협상 스타일 등을 고려하면 지나치게 무리한 계획이라는 지적도 나온다\\xa0조셉 윤 전 국무부 대북정책특별대표는 만약 트럼프 대통령이 정말로 6개월 안에 북한이 아무 보상 없이 핵무기를 넘기는 것을 기대한다면 그것은 매우 비현실적이라며 결국 이전 정부들이 시도했던 방식대로 트럼프 정부 역시 일종의 단계적 조치를 택할 수밖에 없을 것이라고 말했다\\xa0조지 W 부시 행정부에서 아시아 선임보좌관을 지낸 마이클 그린 조지타운대 교수는 포린어페어스에 김 위원장이 트럼프 대통령보다 훨씬 더 큰 그림을 그리고 있다고 지적하기도 했다\\xa0그린 교수는 김정은은 북핵의 미래에 관한 체스판과 동북아의 지정학적 미래에 관한 체스판이라는 두 개의 게임을 놓고 멀티플레이어가 되려 하고 있다며 트럼프 대통령으로서는 잘못된 게임을 준비하고 있는 것인지도 모른다고 말했다', '“갤럭시9 20만 원대 아이폰6 0원!” 모비톡 가정의 달 이벤트갤럭시노트8 갤럭시9 갤럭시8 갤럭시7 갤럭시7엣지 아이폰6 아이폰X 아이폰8 G7 G6 V30 등 다양한 휴대폰 정보가 가득한 스마트폰 공동구매 및 거래 어플 모비톡의 가정의 달 이벤트가 화제다\\xa0모비톡 단독으로 진행되는 5월 가정의 달 이벤트에 이용자들의 폭발적인 반응이 나타나고 있다 고가의 인기 스마트폰을 파격가에 판매한다는 사실에 각종 커뮤니티와 카페를 중심으로 화제를 모으고 있는 것 특히 갤럭시9를 20만 원대 아이폰6는 0원 할부원금을 앞세워 안드로이드와\\xa0i\\xa0인기 기종을 중심으로 큰 폭의 할인을 펼치는게 주된 요인으로 꼽힌다 모비톡 관계자에 따르면 고마운 사람들에게 감사한 마음을 담아 선물할 기회가 많은 5월 가정의 달을 맞아 공격적인 마케팅을 진행하고 있다며 독보적인 통신비 절약 어플로서 앞으로도 최선을 다하겠다고 밝혔다이 밖에도 모비톡은 갤럭시노트8 V30 구매 시 닌텐도 스위치를 증정한다 스마트폰 가격에 버금가는 사은품 제공으로 가계 통신비 절약을 중요시하는 수요층으로부터 긍정적인 반응을 이끌어내고 있다', '스튜디오 측 법적 조치 취할 것 V JP 측 법률 자문 구할 것 A 스튜디오 측이 수지를 향한 법적 조치와 관련해 입장을 밝힌 가운데 수지 측이 법적 자문을 구할 것이라고 밝혔다\\xa0수지 소속사 JP 엔터테인먼트 관계자는 21일 다수의 매체를 통해 수지가 스튜디오 측에 직접 사과의 뜻을 전하고자 하는 의사를 전달했다고 입장을 전했다\\xa0이 관계자는 해당 스튜디오 측이 직접 사과를 받는 것 대신 변호사와 연락해달라는 뜻을 밝혀 를 통해 먼저 사과의 뜻을 전한 것이라며 스튜디오 측의 글을 접했으며 향후 진행 사항은 저희도 법률 대리인에 자문을 구하고 의견에 따를 것이라고 덧붙였다\\xa0앞서 수지는 지난 18일 자신의 인스타그램 스토리에 유튜버 양예원의 성추행 사건과 관련한 청와대 국민 청원을 동의하는 영상을 게재했다\\xa0이 같은 사실이 알려지며 청원 참여 인원이 급증 청원 속 스튜디오는 비난 및 욕설 전화로 업무가 마비되기에 이르렀다그러나 스튜디오가 해당 성추행 사건과 관련이 없는 것으로 확인됐다이에 수지는 19일 를 통해 좋은 뜻으로 하는 일이라도 이런 부분들을 세심하게 살피지 못한 것은 분명 저의 불찰이라고 사과했다\\xa0수지의 사과에도 불구 해당 스튜디오를 향한 비방이 끊이질 않자 해당 스튜디오 측은 21일 공식 팬카페를 통해  게시글 하나에도 수십만명이 클릭하는 수지씨는 분명 본인의 영향력을 충분히 알고 있었을 것이라며 장문을 글을 게재했다\\xa0이어 스튜디오 위치와 상호를 그대로 노출하며 불법을 저질렀다고 낙인하고 있는 청원에 동의하고 나아가 그 사실을 본인의 에 인증하려고 했다면 최소한의 사실관계는 파악해보고 행동했어야 마땅한 거 아닐까 생각해본다며 유명인의 영향력 행사가 무고한 일반인에게 회복할 수 없는 피해와 고통을 줄지 모른다는 생각은 안해봤는지라며 답답한 심경을 토로했다\\xa0스튜디오 측은 부디 이 사건이 유명인의 섣부른 영향력 행사가 얼마나 큰 피해를 초래 할 수 있는지 교훈이 되었으면 좋겠다고 덧붙였다\\xa0그러면서 해당 국민청원 게시자는 물론 신상 유포자들 댓글 테러범들 명예훼손성 청원글을 오랜시간 방치한 청와대 그리고 수지씨의 책임은 법률대리인의 검토를 거쳐 민형사상 필요한 조치를 취할 것이라고 밝혔다', '차명종 서대현 김라희 등 韓7명 호치민3쿠션월드컵 PPPQ통과PPQ에 임정완 강상구 오성욱 등과 총 16명 출전 차명종 서대현 김라희 등 7명이 호치민월드컵 2차예선에 진출했다\\xa0\\xa0 21일 오후 베트남 호치민에서 열린 호치민3쿠션월드컵 1차예선 결과 PPPQ에 출전한 한국선수 20명 중 7명이 각 조1위에 올라 PPQ티켓을 따냈다\\xa0 한국 선수 간 대결이 치러진 AD조에서는 서대현 이재광 임형묵 박동준이 각각 2승으로 조1위에 올랐고 이영민 차명종 김라희가 각각 J M 조에서 외국 선수들과 대결해 2승을 따내며 조1위를 확정지었다\\xa0 PPPQ에 출전한 한국선수 20명 중 절반 이상이 탈락한 가운데 PPQ부터는 임정완 강상구 오성욱 정승일 강인석 서창훈 성상은 김현석 강인원 등 9명이 출전해 PPPQ를 통과한 7명을 포함 총16명의 한국선수가 3차예선 진출을 노린다', ' 예결위는 이날 오전 8시 소소위원회를 열고 전날까지 심사에서 보류된 사업 53건의 감액 심사를 했다 여야 4개 교섭단체의 예결위 간사들만 참석하는 소소위는 심사한 지 한 시간 만에 여야 간 충돌로 정회했다 자유한국당 예결위 간사인 김도읍 의원은 감액할 사업이 많은데 현재 소소위가 정회된 상태라고 말했다예결위는 소소위에서의 감액 심사 완료 및 증액 작업 등을 거쳐 수정된 추경안을 전체회의에 올릴 예정이었으나 현재로서는 전체회의 개의 및 상정 전망이 불투명한 상태다 여야는 예결위 전체회의를 거쳐 이날 오후 9시 국회 본회의에서 추경안을 처리하기로 합의한 상태다 다만 예결위 전체회의가 불발될 경우 본회의에서의 추경안 처리는 어려워질 수 있다', '주유소 가기 무섭다휘발유 가격 근 3년만에 최고치한주만에 ℓ당 129원 급등경유등유도 일제히 연중 최고 이승관   최근 국제유가 상승 등의 영향으로 국내 휘발유와 경유 등유 가격이 일제히 연중 최고치를 갈아치웠다19일 한국석유공사 유가정보 서비스인 오피넷에 따르면 5월 셋째주 국내 주유소에서 판매되는 보통휘발유 가격은 전주보다 ℓ당 129원이나 오른 1천5772원으로 조사됐다4월 셋째주 이후 4주 연속 상승곡선을 그린 것으로 지난 2월 둘째주 기록했던 연중 최고치를 훌쩍 넘어섰다특히 이는 2015년 7월 셋째주 이후 2년 10개월 만에 가장 높은 수치다 최근 3년간 최저점이었던 2016년 3월 둘째주와 비교하면 177나 오른 셈이다국내 주유소 휘발유 가격은 올 2월 둘째주까지 무려 29주 연속 오르며 사상 최장 상승 기록을 세웠으나 이후 4월 셋째주까지 하강 곡선을 그리다 또다시 급격히 반등하는 추세다자동차용 경유와 실내 등유 가격도 최근 몇주간 가파른 상승세를 이어가며 또다시 연중 최고치를 기록했다 5월 셋째주 경유 판매가격은 141원 오른 1천3773원 등유는 60원 오른 9169원을 각각 기록했다 상표별로는 가장 가격이 낮은 알뜰주유소에서 휘발유 가격이 전주보다 122원 오른 1천5490원이었고 경유는 131원 오른 1천3499원에 달했다가장 높은 상표는 K에너지로 휘발유와 경유가 각각 전주보다 115원과 127원 오른 1천5938원 1천3939원이었다지역별로는 최고가 지역인 서울의 휘발유 가격이 1천6662원으로 전국 평균 가격보다 890원 높았다 대구는 1천5508원으로 전국에서 가장 낮은 것으로 조사됐다석유공사는 국제유가가 중동의 지정학적 리스크와 미국 원유제품의 재고 감소 등의 영향으로 상승했다면서 이에 따라 국내 제품 가격도 오름세가 지속될 것으로 전망된다고 밝혔다5월 둘째주 정유사의 휘발유 공급가격은 전주보다 ℓ당 무려 433원 상승한 1천5090원을 기록했다 경유 가격도 595원 오른 1천3287원 등유도 459원 오른 8273원이었다']\n"
     ]
    }
   ],
   "source": [
    "print(Xdata[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To build better word2vec model. use extra corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataForVec = list(Xdata)\n",
    "\n",
    "corpus=[]\n",
    "f = open(\"./corpusAll.txt\", 'r')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    corpus.append(line)\n",
    "f.close()\n",
    "\n",
    "corpus = text_cleaner(corpus)\n",
    "print(len(corpus))\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    dataForVec.append(corpus[i])\n",
    "    \n",
    "dataForVec = dataForVec[:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataForVec))\n",
    "print(dataForVec[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Nouns and Verbs Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphs_process(lines, tagger):\n",
    "    sentences = []\n",
    "    for line in lines:\n",
    "        sentence = []\n",
    "        pos = tagger.pos(line)\n",
    "        for pair in pos:\n",
    "            if (pair[1] in ['NNG','NNP','NNB'\n",
    "                            ,'NNBC','NR','NP'\n",
    "                            ,'VV','VA','VX'\n",
    "                            ,'VCP','VCN']) :\n",
    "                morpheme = pair[0]\n",
    "                sentence.append(morpheme)\n",
    "            else:\n",
    "                pass\n",
    "        sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenExport(tokens, filename):\n",
    "    f = open(filename, 'w')\n",
    "    f.write('\\n')\n",
    "    for line in tokens:\n",
    "        f = open(filename, 'a')\n",
    "        f.writelines(' '.join(line))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mec = konlpy.tag.Mecab()\n",
    "tw = konlpy.tag.Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = morphs_process(Xtrain, mec)\n",
    "Xtest = morphs_process(Xtest, mec) \n",
    "Xdata = morphs_process(Xdata, mec)\n",
    "dataForVec = morphs_process(dataForVec, mec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['동남아', '담당', '北', '최희철', '부상', '베이징', '도착', '싱가포르', '주목', '부상', '행선', '지방문', '목적', '질문', '묵묵부답', '김진방', '북한', '북미', '정상', '회담', '무산', '가능', '거론', '태도', '보이', '가운데', '동남아시아', '외교', '담당', '최희철', '북한', '외무성', '부상', '일', '중국', '베이징', '서우', '공항', '모습', '부상', '이날', '오전', '평', '양발', '고려항공', '편', '이용', '베이징', '서우', '공항', '도착', '부상', '최종', '목적지', '묻', '취재진', '질문', '답변', '하', '않', '북한', '대사관', '관계자', '공항', '북미', '정상', '회담', '일', '상황', '동남아', '외교통', '부상', '정상', '회담', '준비', '등', '회담', '개최', '예정지', '싱가포르', '방문', '가능', '제기', '있', '부상', '월', '아세안', '의장국', '이', '싱가포르', '방문', '양국', '관계', '올해', '월', '열리', '아세안', '지역', '안보', '포럼', '의제', '등', '논의', '바', '있', '지난해', '북', '핵', '문제', '두', '북미', '간', '긴장', '관계', '형성', '때', '참석', '아세안', '상대', '여론전', '북한', '초청', '비자이', '쿠마르', '싱', '인도', '외교부', '국무', '장관', '방북', '때', '부상', '싱', '국무', '장관', '영접', '한반도', '문제', '논의', '베이징', '소식통', '부상', '대미', '외교', '담당', '아니', '때문', '싱가포르', '가능', '것', '아니', '만약', '싱가포르', '정상', '회담', '관련', '지원', '작업', '준비', '등', '것', '가능', '크', '말'], ['달', '번', '연구', '단지', '대통령', '국민', '선출', '일국', '대통령', '이', '자리', '어마', '무시', '행정', '수반', '이', '외교', '국가', '대표', '얼굴', '이', '대부분', '군', '통수권', '갖', '있', '막강', '권한', '국민', '관심', '집중', '말', '한마디', '행동', '옷차림', '먹', '음식', '순식간', '가', '표정', '의미', '담', '의도', '없', '거기', '맥락', '뽑아내', '열심', '이', '문재인', '대통령', '마찬가지', '대통령', '보좌', '청와대', '수많', '수석', '비서관', '등', '국정', '철학', '극대', '효과', '메시지', '전달', '골몰', '한반도', '운명', '중요', '회담', '눈앞', '데', '댓글', '조작', '드루', '특검', '법', '추가경정예산', '안', '두', '여야', '격돌', '요즘', '같', '때', '분위기', '논란', '사전', '차단', '대통령', '동선', '달', '대통령', '번', '발길', '곳', '있', '서울', '강서구', '마곡동', '조성', '융', '복합', '연구', '개발', '사이언스', '파크', '방문', '지난달', '일', '년', '삽', '사이언', '스파크', '년', '개월', '만', '완성', '이날', '개장식', '구본준', '부회장', '허창수', '회장', '등', '대통령', '문', '대통령', '디스플레이', '개발', '두루마리', '디스플레이', '전자', '인공지능', '로봇', '미래형', '계기판', '적용', '자동차', '모형', '등', '체험', '홍보', '효과', '얻', '기업', '친하', '않', '문', '대통령', '지주회사', '체재', '완성', '것', '같', '문', '대통령', '축사', '중', '기업', '중소기업', '상생', '협력', '창업', '수', '있', '동반', '성장', '모범', '달', '언급', '사이언', '스파크', '번', '방문', '일', '날짜', '따지', '일', '만', '상황', '검찰', '일', '억', '원', '양도', '소득세', '탈루', '혐의', '서울', '여의도', '트윈', '타워', '본사', '전격', '압수수색', '수사', '진행', '중', '이', '기업', '이', '등식', '흠', '문', '대통령', '김정은', '북한', '국무', '위원장', '지난달', '일', '판문점', '평화', '집', '정상', '회담', '남북', '관계', '급진전', '남북', '문제', '분수령', '있', '문', '대통령', '달', '같', '장소', '기업', '단지', '방문', '것', '이례', '이번', '주', '문', '대통령', '외부', '공식', '일정', '이거', '하나', '일', '광주', '주년', '민주', '운동', '기념식', '이낙연', '국무총리', '보내', '불참', '일', '미국', '열리', '한미정상회담', '다음', '달', '일', '싱가포르', '예정', '북미', '정상', '회담', '준비', '전념', '것', '사이언스', '파크', '이유', '년', '대한민국', '혁신', '성장', '보', '대회', '답', '있', '것', '같', '이날', '지난해', '연말', '확정', '성장', '동력', '성과', '점검', '세부', '추진', '계획', '공유', '자리', '관계', '부처', '논의', '경기', '성남시', '판교', '테크노', '밸리', '사이언', '스파크', '등', '복수', '후보지', '추천', '장소', '확정', '것', '청와대', '청와대', '측', '출입', '질문', '실내', '드론', '작동', '만', '장소', '적합', '뿐', '의미', '없', '설명', '문재인', '정부', '경제', '정책', '축', '소득', '주도', '성장', '혁신', '성장', '최저', '임금', '인상', '근로', '시간', '단축', '등', '소득', '주도', '성장', '년', '만', '속도', '진행', '있', '혁신', '성장', '더디', '국민', '체감', '수준', '그렇', '혁신', '성장', '성공', '이', '평가', '경제', '전문가', '보이', '않', '문', '대통령', '이날', '무엇', '중요', '것', '속도', '이', '국민', '성과', '체감', '혁신', '성장', '붐', '강조', '재계', '일말', '기대감', '감지', '역사', '북미', '정상', '회담', '앞', '먹', '사', '문제', '중요', '대통령', '메시지', '해석', '분배', '경제', '무게', '중심', '성장', '쪽', '조금', '이동', '않', '생각', '뇌', '피', '셜'], ['급', '공무원', '만', '명', '수험', '피', '시', '서울', '제외', '전국', '급', '지방', '직', '공무원', '시험', '만', '명', '넘', '수험', '응시', '어제', '오늘', '이틀', '간', '모습', '배영진', '가', '취재', '급', '지방', '직', '공무원', '시험', '하루', '전', '수험', '숨죽이', '문제', '문제', '집중', '각자', '방식', '정리', '하', '결전', '의지', '다지', '얼굴', '숨소리', '들리', '않', '시험', '하루', '남', '않', '시간', '수험', '문제', '당락', '결정', '수', '있', '생각', '오늘', '싸움', '이', '가', '있', '결혼', '연애', '출산', '포기', '포', '세대', '마지막', '신', '직장', '불리', '지방', '직', '급', '공무원', '올해', '선발', '인원', '만', '천', '백', '명', '지난해', '천', '백', '명', '늘', '경쟁', '대', '기록', '문제', '분', '안', '정확', '풀어내', '하', '수험', '달', '전', '긴장', '남', '컨디션', '조절', '평소', '체크', '놓', '색깔', '다르', '마지막', '때', '수', '있', '마지막', '날', '이', '책', '보', '앉', '있', '눈', '들어가', '쉬', '편', '결전', '날', '밝', '아침', '수험', '국어', '영어', '한국사', '등', '과목', '푸', '실전', '분', '간', '적막', '끝나', '표정', '시험장', '끝나', '기분', '결과', '거', '같', '예상', '문제', '마음', '기분', '좋', '않', '않', '거', '같', '시험', '뒤', '고사장', '수험', '열기', '남', '있', '채널', '뉴스', '배영진'], ['월요일', '일교차', '감기', '조심', '월요일', '일교차', '감기', '조심', '화창', '나', '하', '좋', '휴일', '마무리', '하', '징검다리', '연휴', '동안', '특별', '계획', '있', '날씨', '불편', '없', '내일', '하늘', '구름', '끼', '기온', '서울', '도로', '오늘', '요석', '가탄', '신일', '화요일', '도로', '예년', '이맘때', '수준', '보이', '하늘', '밤', '전국', '비', '내리', '전국', '하늘', '맑', '밤', '구름', '많', '지', '안가', '중심', '바람', '강하', '불', '시설물', '피해', '없', '점검', '아침', '강원', '영동', '안개', '끼', '곳', '있', '출근길', '교통', '안전', '유의', '아침', '기온', '서울', '도', '대구', '도', '전주', '도로', '오늘', '높', '낮', '서울', '도', '춘천', '도', '전주', '도로', '대부분', '도', '안팎', '덥', '바닷바람', '불어오', '동해안', '지역', '강릉', '도', '등', '내륙', '상대', '기온', '낮', '동해', '남해', '풍랑', '특보', '있', '물결', '최고', '높', '것', '항해', '조업', '시', '조심', '화요일', '밤', '시작', '비', '수요일', '오전', '그치', '이후', '맑', '날씨', '속', '기온', '도', '웃돌', '일교차', '계속', '크', '건강', '관리', '주', '날씨'], ['화난', '트럼프', '북미', '회담', '계속', '하나', '측근', '트럼프', '불편', '심기', '주', '신호', '참모', '협상력', '우려', '이윤영', '다음', '달', '북미', '정상', '회담', '정치', '낭패', '수', '있', '도널드', '트럼프', '대통령', '우려', '커지', '트럼프', '대통령', '참모', '압박', '시작', '미국', '유력', '신문', '뉴욕', '타임스', '보도', '역사', '이번', '북미', '회담', '진행', '위험', '부담', '떠안', '가', '하', '최근', '며칠', '간', '참모', '질문', '퍼부', '것', '이', '일', '미', '정부', '외국', '정부', '관계자', '인용', '같', '백악관', '내부', '분위기', '따르', '트럼프', '대통령', '일방', '핵', '포기', '강요', '북미', '정상', '회담', '고려', '수', '있', '일', '김계관', '북한', '외무', '부상', '담화', '발표', '것', '이', '트럼프', '대통령', '일', '참모', '회담', '계속', '진행', '것', '참모', '질문', '공세', '이', '일', '밤', '문재인', '대통령', '전화', '통화', '하', '북한', '공식', '담화', '내용', '대통령', '자신', '전달', '내용', '상충', '물', '이날', '통화', '문', '대통령', '워싱턴', '방문', '사흘', '앞두', '것', '이', '이', '두', '미', '정부', '일각', '문', '대통령', '워싱턴', '때', '수', '없', '트럼프', '대통령', '불편', '심기', '주', '것', '이', '해석', '참모', '트럼프', '대통령', '노벨', '상', '염두', '두', '이번', '회담', '지나치', '갈망', '듯', '신호', '점', '우려', '나타내', '있', '트럼프', '대통령', '열망', '김정은', '북한', '국무', '위원장', '비핵화', '협상', '시간', '지나', '약속', '수', '있', '것', '이', '참모', '우려', '가지', '비핵화', '협상', '미국', '양보', '수', '없', '핵심', '요소', '트럼프', '대통령', '이해', '하', '있', '것', '세부', '협상', '계획', '트럼프', '대통령', '카드', '가지', '있', '것', '이', '최근', '차례', '방북', '마치', '마이크', '폼페이', '오', '국무부', '장관', '김', '위원장', '논의', '능', '정도', '평가', '내놓', '바', '있', '트럼프', '대통령', '전임', '버락', '오바마', '조지', '부시', '대통령', '우라늄', '농축', '능력', '플루토늄', '재처리', '핵무기', '생산', '미사일', '프로그램', '등', '브리핑', '듣', '것', '견디', '참모', '전언', '이', '미', '정부', '관계자', '김', '위원장', '이번', '북미', '회담', '향후', '개월', '내', '핵무기', '일부', '넘기', '관련', '시설', '폐쇄', '사찰', '허용', '타임', '테이블', '동의', '것', '예상', '말', '실제', '일', '일본', '아사히', '신문', '미국', '사전', '협상', '북한', '보유', '핵탄두', '핵', '관련', '물질', '등', '일부', '개월', '안', '해외', '반출', '것', '요구', '보도', '같', '스케줄', '과거', '북한', '전통', '협상', '스타일', '등', '고려', '지나치', '무리', '계획', '이', '지적', '조셉', '윤', '국무부', '대북', '정책', '특별', '대표', '만약', '트럼프', '대통령', '개월', '안', '북한', '보상', '핵무기', '넘기', '것', '기대', '그것', '현실', '이', '결국', '이전', '정부', '시도', '방식', '트럼프', '정부', '일종', '단계', '조치', '수', '없', '것', '이', '말', '조지', '부시', '행정부', '아시아', '선임', '보좌관', '마이클', '그린', '조지타운', '교수', '포린', '어페어스', '김', '위원장', '트럼프', '대통령', '그림', '그리', '있', '지적', '교수', '김정은', '북', '핵', '미래', '체스', '판', '동북아', '지정학', '미래', '체스', '판', '이', '개', '게임', '놓', '멀티', '플레이어', '하', '있', '트럼프', '대통령', '게임', '준비', '있', '것', '말'], ['갤럭시', '만', '원', '대', '아이폰', '원', '모비', '톡', '가정', '달', '이벤트', '갤럭시', '노트', '갤럭시', '갤럭시', '갤럭시', '갤럭시', '엣지', '아이폰', '아이폰', '아이폰', '등', '다양', '휴대폰', '정보', '스마트폰', '공동', '구매', '거래', '플', '모비', '톡', '가정', '달', '이벤트', '화제', '모비', '톡', '단독', '진행', '월', '가정', '달', '이벤트', '이용자', '폭발', '반응', '나타나', '있', '고가', '인기', '스마트폰', '파격', '판매', '사실', '각종', '커뮤니티', '카페', '중심', '화제', '모으', '있', '것', '갤럭시', '만', '원', '대', '아이폰', '원', '할부', '원금', '안드로이드', '인기', '기종', '중심', '폭', '할인', '펼치', '요인', '모비', '톡', '관계자', '따르', '사람', '감사', '마음', '담', '선물', '기회', '많', '월', '가정', '달', '맞', '공격', '마케팅', '진행', '있', '독보', '통신비', '절약', '플', '앞', '최선', '하', '밖', '모비', '톡', '갤럭시', '노트', '구매', '시', '닌텐도', '스위치', '증정', '스마트폰', '가격', '버금가', '사은품', '제공', '가계', '통신비', '절약', '중요', '수요층', '긍정', '반응', '이끌', '내', '있'], ['스튜디오', '측', '법', '조치', '것', '측', '법률', '자문', '것', '스튜디오', '측', '수지', '법', '조치', '관련', '입장', '가운데', '수지', '측', '법', '자문', '것', '이', '수지', '소속', '사', '엔터', '테', '트', '관계자', '일', '다수', '매체', '수지', '스튜디오', '측', '사과', '뜻', '전하', '하', '의사', '전달', '입장', '관계자', '해당', '스튜디오', '측', '사과', '받', '것', '대신', '변호사', '연락', '달', '뜻', '사과', '뜻', '것', '이', '스튜디오', '측', '글', '향후', '진행', '사항', '저희', '법률', '대리인', '자문', '구하', '의견', '것', '이', '수지', '일', '자신', '인', '스타', '그램', '스토리', '유', '튜버', '양', '예원', '성추행', '사건', '관련', '청와대', '국민', '청원', '동의', '영상', '게재', '같', '사실', '지', '청원', '참여', '인원', '급증', '청원', '속', '스튜디오', '비난', '욕설', '전화', '업무', '마비', '이르', '스튜디오', '해당', '성추행', '사건', '관련', '없', '것', '확인', '이', '수지', '일', '좋', '뜻', '하', '일', '이', '부분', '세심', '살피', '것', '저', '불찰', '이', '사과', '수지', '사과', '해당', '스튜디오', '비방', '끊이', '않', '해당', '스튜디오', '측', '일', '공식', '팬', '카페', '게시', '글', '하나', '수십만', '명', '클릭', '수지', '씨', '본인', '영향', '알', '있', '것', '이', '장문', '글', '게재', '이', '스튜디오', '위치', '상호', '노출', '불법', '낙인', '있', '청원', '동의', '사실', '본인', '인증', '최소한', '사실', '관계', '파악', '보', '행동', '거', '생각', '유명', '영향력', '행사', '일반인', '회복', '수', '없', '피해', '고통', '생각', '심경', '토로', '스튜디오', '측', '사건', '유명', '영향력', '행사', '피해', '초래', '수', '있', '교훈', '되', '좋', '그러', '해당', '국민', '청원', '게시', '신상', '유포', '댓글', '테러', '범', '명예', '훼손', '청원', '글', '시간', '방치', '청와대', '수지', '씨', '책임', '법률', '대리인', '검토', '민형사', '필요', '조치', '것', '이'], ['차', '명종', '서대현', '김라희', '등', '韓', '명', '호치민', '쿠션', '월드컵', '통과', '임정완', '강상구', '오성욱', '등', '명', '출전', '차', '명종', '서대현', '김라희', '등', '명', '호치민', '월드컵', '차', '예선', '진출', '일', '오후', '베트남', '호치민', '호치민', '쿠션', '월드컵', '차', '예선', '결과', '출전', '한국', '선수', '명', '중', '명', '조', '위', '티켓', '한국', '선수', '간', '대결', '조', '서대현', '이재광', '임형묵', '박동준', '승', '조', '위', '이영민', '차', '명종', '김라희', '조', '외국', '선수', '대결', '승', '따내', '조', '위', '확정', '지', '출전', '한국', '선수', '명', '중', '절반', '이상', '가운데', '임정완', '강상구', '오성욱', '정승일', '강인석', '서창훈', '성상', '김현석', '강인원', '등', '명', '출전', '통과', '명', '포함', '명', '한국', '선수', '차', '예선', '진출'], ['예결', '위', '이날', '오전', '시', '소소', '위원회', '열', '전날', '심사', '보류', '사업', '건', '감액', '심사', '여야', '개', '교섭단체', '예결', '위', '간사', '참석', '소소', '위', '심사', '지', '시간', '만', '여야', '간', '충돌', '정회', '자유', '국당', '예결', '위', '간사인', '김도읍', '의원', '감액', '사업', '많', '소소', '위', '정회', '상태', '말', '예결', '위', '소소', '위', '감액', '심사', '완료', '증액', '작업', '등', '수정', '추경', '안', '전체', '회의', '예정', '이', '현재', '전체', '회의', '개의', '상정', '전망', '투명', '상태', '여야', '예결', '위', '전체', '회의', '이날', '오후', '시', '국회', '본회의', '추경', '안', '처리', '합의', '상태', '예결', '위', '전체', '회의', '불발', '경우', '본회의', '추경', '안', '처리', '수', '있'], ['주유소', '가', '무섭', '휘발유', '가격', '년', '만', '고치', '주만', '원', '급등', '경유', '등유', '연중', '최고', '이승관', '최근', '국제', '유가', '상승', '등', '영향', '국내', '휘발유', '경유', '등유', '가격', '연중', '최고', '갈', '일', '한국', '석유공사', '유가', '정보', '서비스', '오피', '넷', '따르', '월', '셋째', '주', '국내', '주유소', '판매', '보통', '휘발유', '가격', '전주', '원', '천', '원', '조사', '월', '셋째', '주', '이후', '주', '연속', '상승', '곡선', '것', '월', '둘째', '주', '기록', '연중', '최고', '이', '년', '월', '셋째', '주', '이후', '년', '개월', '만', '높', '수', '치', '최근', '년', '간', '최저', '점', '이', '년', '월', '둘째', '주', '비교', '나', '셈', '이', '국내', '주유소', '휘발유', '가격', '월', '둘째', '주', '주', '연속', '오르', '사상', '최장', '상승', '기록', '이후', '월', '셋째', '주', '하강', '곡선', '반등', '추세', '자동차', '경유', '실내', '등유', '가격', '최근', '주간', '상승세', '이', '가', '연중', '최고', '기록', '월', '셋째', '주', '경유', '판매', '가격', '원', '천', '원', '등유', '원', '원', '기록', '상표', '가격', '낮', '알뜰', '주유소', '휘발유', '가격', '전주', '원', '천', '원', '이', '경유', '원', '천', '원', '높', '상표', '에너지', '휘발유', '경유', '전주', '원', '원', '천', '원', '천', '원', '이', '지역', '최고', '지역', '서울', '휘발유', '가격', '천', '원', '전국', '평균', '가격', '원', '높', '대구', '천', '원', '전국', '낮', '것', '조사', '석유공사', '국제', '유가', '중동', '지정학', '리스크', '미국', '원유', '제품', '재고', '감소', '등', '영향', '상승', '이', '국내', '제품', '가격', '오름세', '지속', '것', '전망', '월', '둘째', '주', '정유', '사', '휘발유', '공급', '가격', '전주', '원', '상승', '천', '원', '기록', '경유', '가격', '원', '천', '원', '등유', '원', '원', '이']]\n",
      "1280\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain[:10])\n",
    "print(len(Xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenExport(dataForVec, 'tokens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataForVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vector Model\n",
    "### FT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ftmodelmake(data, model, lr = 0.1, dim = 300, ws = 5, min_count = 10):\n",
    "    model = fasttext.skipgram(data, model, lr = lr, dim = dim, ws = ws, min_count = min_count)\n",
    "    print(len(model.words))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftmodel = ftmodelmake('tokens.txt', 'ftmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ftModel = KeyedVectors.load_word2vec_format('ftmodel.vec')\n",
    "ftVocab= list(ftModel.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarTest(model, word):\n",
    "    ftsimilars = model.most_similar(positive=[word], topn=10)\n",
    "    for word, value in ftsimilars:\n",
    "        print(word, value)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도널드 0.5814574956893921\n",
      "오바마 0.47336798906326294\n",
      "비핵화 0.43146321177482605\n",
      "백악관 0.4286015033721924\n",
      "줄리아니 0.42347168922424316\n",
      "허커비 0.41646575927734375\n",
      "대통령 0.4144159257411957\n",
      "버락 0.4141687750816345\n",
      "공화 0.4085821807384491\n",
      "회담 0.3984195291996002\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "similarTest(ftModel, '트럼프')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebdIdx(model, vocab_list):\n",
    "    embd_idx = {}\n",
    "\n",
    "    for w in vocab_list:\n",
    "        embd_idx[w] = model.__getitem__(w)\n",
    "\n",
    "    print(len(embd_idx))\n",
    "    return embd_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32707\n"
     ]
    }
   ],
   "source": [
    "embedding_idx = ebdIdx(ftModel, ftVocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Data Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequence(text, MAX_FEATURES, word_index):\n",
    "    seq = []\n",
    "    for line in text:\n",
    "        lineseq = []\n",
    "        for i in range(len(line)):\n",
    "            if (word_index[line[i]] < MAX_FEATURES):\n",
    "                lineseq.append(word_index[line[i]])\n",
    "            else:\n",
    "                pass\n",
    "        seq.append(lineseq)\n",
    "    seq = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    seq = np.array(seq)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32707\n"
     ]
    }
   ],
   "source": [
    "MAX_FEATURES = len(embedding_idx)\n",
    "MAX_SEQUENCE_LENGTH = 525\n",
    "EMBEDDING_DIM = 300\n",
    "print(MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  7,  21,  36,  63,  79, 102,  70,  74,  96,  99,  93,  88,  74,\n",
       "         73,  80,  65,  78,  40,  52,  47,  30,  22,  41,  20,  32,  29,\n",
       "         22,   9,   7,   9,   7,   7,   5,   6,   1,   2,   3,   2,   2,\n",
       "          3,   0,   2,   1,   0,   0,   0,   0,   0,   0,   1]),\n",
       " array([ 53.  ,  66.36,  79.72,  93.08, 106.44, 119.8 , 133.16, 146.52,\n",
       "        159.88, 173.24, 186.6 , 199.96, 213.32, 226.68, 240.04, 253.4 ,\n",
       "        266.76, 280.12, 293.48, 306.84, 320.2 , 333.56, 346.92, 360.28,\n",
       "        373.64, 387.  , 400.36, 413.72, 427.08, 440.44, 453.8 , 467.16,\n",
       "        480.52, 493.88, 507.24, 520.6 , 533.96, 547.32, 560.68, 574.04,\n",
       "        587.4 , 600.76, 614.12, 627.48, 640.84, 654.2 , 667.56, 680.92,\n",
       "        694.28, 707.64, 721.  ]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(Xdata)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(Xdata)\n",
    "seqlen = np.array([len(sequence) for sequence in sequences])\n",
    "np.histogram(seqlen, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = getSequence(Xtrain, MAX_FEATURES, word_index)\n",
    "x_test = getSequence(Xtest, MAX_FEATURES, word_index)\n",
    "y_train = to_categorical(np.asarray(Ytrain))\n",
    "y_test = to_categorical(np.asarray(Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train tensor: (1280, 525)\n",
      "Shape of y_train tensor: (1280, 8)\n",
      "Shape of x_test tensor: (320, 525)\n",
      "Shape of y_test tensor: (320, 8)\n",
      "20861\n",
      "1.0\n",
      "[ 4445   878   905 11254   700   957  1129   982   561   700 14625 14626\n",
      "  1189   413  5495  7241    23   150    30    25  1705    52  1407   931\n",
      "   219   189 11255   562   878 11254    23  2648   700     4    35   957\n",
      "  9402   790   117   700    39   158  2878 14627  7242   729   169   957\n",
      "  9402   790  1129   700   528  6544   893  1878   413  1430     9     8\n",
      "    23  1431    65   790   150    30    25     4    72  4445 14628   700\n",
      "    30    25   261     5    25   252 11256   982   464    52   322     1\n",
      "   700    13  5496 11257     2   982   464  1602   140   133    13   407\n",
      "  5496    87   996  3002  3407     5   295   178     1    63   311   156\n",
      "    58   286   150    85  1504   140  1265    31   421  5496   271 14629\n",
      "    23  1432 14630 14631  3945   808  2408   587   276  1639    31   700\n",
      "  3945   587   276  8180   364    58   295   957  1640   700  3103   562\n",
      "   878    41    34   982    52     3    41  1641   982    30    25    38\n",
      "   181   591   261     5     3    52   171    10     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('Shape of x_train tensor:', x_train.shape)\n",
    "print('Shape of y_train tensor:', y_train.shape)\n",
    "print('Shape of x_test tensor:', x_test.shape)\n",
    "print('Shape of y_test tensor:', y_test.shape)\n",
    "print(np.amax(x_train))\n",
    "print(np.amax(y_train))\n",
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix...\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix...')\n",
    "\n",
    "num_words = min(MAX_FEATURES, len(ftVocab) + 1) #unknown word 때문에 +1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_FEATURES:\n",
    "        continue\n",
    "    embedding_vector = embedding_idx.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix], \n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32707, 300)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Build, Train & Evaluate\n",
    "### Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where all models are saved\n",
    "BASE_PATH = './model_180715/'\n",
    "if not os.path.exists(BASE_PATH):\n",
    "    os.mkdir(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checkpoint(model_name):\n",
    "    MODEL_PATH = os.path.join(BASE_PATH, model_name)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.mkdir(MODEL_PATH)\n",
    "    \n",
    "    return ModelCheckpoint(filepath=os.path.join(MODEL_PATH, 'val_loss-{val_loss:.4f}.hdf5'),\n",
    "                           monitor='val_loss',\n",
    "                           verbose=1,\n",
    "                           save_best_only=True)\n",
    "\n",
    "def create_checkpoint2(model_name):\n",
    "    MODEL_PATH = os.path.join(BASE_PATH, model_name)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.mkdir(MODEL_PATH)\n",
    "    \n",
    "    return ModelCheckpoint(filepath=os.path.join(MODEL_PATH, 'val_acc-{val_acc:.4f}.hdf5'),\n",
    "                           monitor='val_acc',\n",
    "                           verbose=1,\n",
    "                           save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_epochs = 100\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTMmodel(hiddenlayer = 64, drop = 0.5):\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    dropout = Dropout(drop)(embedded_sequences)\n",
    "\n",
    "    lstm_1 = Bidirectional(LSTM(hiddenlayer, return_sequences=True))(dropout)\n",
    "    lstm_2 = Bidirectional(LSTM(hiddenlayer, return_sequences=True))(lstm_1)\n",
    "    lstm_3 = Bidirectional(LSTM(hiddenlayer, return_sequences=True))(lstm_2)\n",
    "    lstm_4 = Bidirectional(LSTM(hiddenlayer))(lstm_3)\n",
    "    preds = Dense(8, activation='softmax')(lstm_4)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    checkloss = create_checkpoint('LSTM') \n",
    "    checkacc = create_checkpoint2('LSTM')\n",
    "\n",
    "    print('Training...')\n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=max_epochs,\n",
    "              validation_split=0.15,\n",
    "              shuffle=True,\n",
    "              callbacks=[checkloss, checkacc, early_stopping])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN - GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRUmodel(hiddenlayer = 64, drop = 0.5):\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    dropout = Dropout(drop)(embedded_sequences)\n",
    "\n",
    "    gru_1 = Bidirectional(GRU(hiddenlayer, return_sequences=True))(dropout)\n",
    "    gru_2 = Bidirectional(GRU(hiddenlayer, return_sequences=True))(gru_1)\n",
    "    gru_3 = Bidirectional(GRU(hiddenlayer, return_sequences=True))(gru_2)\n",
    "    gru_4 = Bidirectional(GRU(hiddenlayer))(gru_3)\n",
    "    preds = Dense(8, activation='softmax')(gru_4)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    checkloss = create_checkpoint('GRU') \n",
    "    checkacc = create_checkpoint2('GRU')\n",
    "    \n",
    "    print('Training...')\n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=max_epochs,\n",
    "              validation_split = 0.15,\n",
    "              shuffle=True,\n",
    "              callbacks=[checkloss, checkacc, early_stopping])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNModel(num_filters = 128, drop =0.7):\n",
    "    filter_sizes = [3,4,5,6]\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    reshape = Reshape((MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,1))(embedded_sequences)\n",
    "\n",
    "    conv_0 = Conv2D(num_filters, \n",
    "                    kernel_size=(filter_sizes[0], EMBEDDING_DIM), \n",
    "                    padding='valid', \n",
    "                    kernel_initializer='normal', \n",
    "                    activation='relu')(reshape)\n",
    "    conv_1 = Conv2D(num_filters, \n",
    "                    kernel_size=(filter_sizes[1], EMBEDDING_DIM), \n",
    "                    padding='valid', \n",
    "                    kernel_initializer='normal', \n",
    "                    activation='relu')(reshape)\n",
    "    conv_2 = Conv2D(num_filters, \n",
    "                    kernel_size=(filter_sizes[2], EMBEDDING_DIM), \n",
    "                    padding='valid', \n",
    "                    kernel_initializer='normal', \n",
    "                    activation='relu')(reshape)\n",
    "    conv_3 = Conv2D(num_filters, \n",
    "                    kernel_size=(filter_sizes[3], EMBEDDING_DIM), \n",
    "                    padding='valid', \n",
    "                    kernel_initializer='normal', \n",
    "                    activation='relu')(reshape)\n",
    "\n",
    "\n",
    "    maxpool_0 = MaxPooling2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[0] + 1, 1), \n",
    "                             strides=(1,1), \n",
    "                             padding='valid')(conv_0)\n",
    "    maxpool_1 = MaxPooling2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[1] + 1, 1), \n",
    "                             strides=(1,1), \n",
    "                             padding='valid')(conv_1)\n",
    "    maxpool_2 = MaxPooling2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[2] + 1, 1), \n",
    "                             strides=(1,1), \n",
    "                             padding='valid')(conv_2)\n",
    "    maxpool_3 = MaxPooling2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[3] + 1, 1), \n",
    "                             strides=(1,1), \n",
    "                             padding='valid')(conv_3)\n",
    "\n",
    "    concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])\n",
    "    flatten = Flatten()(concatenated_tensor)\n",
    "    dropout = Dropout(drop)(flatten)\n",
    "    preds = Dense(8, activation='softmax')(dropout)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    checkloss = create_checkpoint('CNN') \n",
    "    checkacc = create_checkpoint2('CNN')\n",
    "    \n",
    "    print('Training...')\n",
    "    history = model.fit(x_train, y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=max_epochs, \n",
    "              verbose=1, \n",
    "              shuffle=True,\n",
    "              callbacks=[checkloss, checkacc, early_stopping], \n",
    "              validation_split=0.15) \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNLSTMModel(filter_sizes = 128, drop = 0.5):    \n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    dropout = Dropout(drop)(embedded_sequences)\n",
    "    \n",
    "    conv_0 = Conv1D(filter_sizes, 5, activation='relu')(dropout)\n",
    "    maxpool_0 = MaxPooling1D(pool_size=4)(conv_0)\n",
    "    conv_1 = Conv1D(filter_sizes, 5, activation='relu')(maxpool_0)\n",
    "    maxpool_1 = MaxPooling1D(pool_size=4)(conv_1)\n",
    "    conv_2 = Conv1D(filter_sizes, 5, activation='relu')(maxpool_1)\n",
    "    maxpool_2 = MaxPooling1D(pool_size=4)(conv_2)\n",
    "    lstm = LSTM(128)(maxpool_2)\n",
    "    preds = Dense(8, activation='softmax')(lstm)\n",
    "    \n",
    "    model = Model(sequence_input, preds)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    checkloss = create_checkpoint('CNN+LSTM') \n",
    "    checkacc = create_checkpoint2('CNN+LSTM')\n",
    "    \n",
    "    print('Training...')\n",
    "    history = model.fit(x_train, y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=max_epochs, \n",
    "              verbose=1, \n",
    "              callbacks=[early_stopping, checkloss, checkacc], \n",
    "              validation_split = 0.15) \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN+GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNGRUModel(filter_sizes = 128, drop = 0.5):\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    dropout = Dropout(drop)(embedded_sequences)\n",
    "    \n",
    "    conv_0 = Conv1D(filter_sizes, 5, activation='relu')(dropout)\n",
    "    maxpool_0 = MaxPooling1D(pool_size=4)(conv_0)\n",
    "    conv_1 = Conv1D(filter_sizes, 5, activation='relu')(maxpool_0)\n",
    "    maxpool_1 = MaxPooling1D(pool_size=4)(conv_1)\n",
    "    conv_2 = Conv1D(filter_sizes, 5, activation='relu')(maxpool_1)\n",
    "    maxpool_2 = MaxPooling1D(pool_size=4)(conv_2)\n",
    "    gru = GRU(128)(maxpool_2)\n",
    "    preds = Dense(8, activation='softmax')(gru)\n",
    "    \n",
    "    model = Model(sequence_input, preds)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    checkloss = create_checkpoint('CNN+GRU') \n",
    "    checkacc = create_checkpoint2('CNN+GRU')\n",
    "    \n",
    "    print('Training...')\n",
    "    history = model.fit(x_train, y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=max_epochs, \n",
    "              verbose=1, \n",
    "              callbacks=[early_stopping, checkloss, checkacc], \n",
    "              validation_split = 0.15) \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTMmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = GRUmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 525)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 525, 300)     9812100     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 525, 300, 1)  0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 523, 1, 128)  115328      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 522, 1, 128)  153728      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 521, 1, 128)  192128      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 520, 1, 128)  230528      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 1, 128)    0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            4104        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,507,916\n",
      "Trainable params: 695,816\n",
      "Non-trainable params: 9,812,100\n",
      "__________________________________________________________________________________________________\n",
      "Training...\n",
      "Train on 1088 samples, validate on 192 samples\n",
      "Epoch 1/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 2.8640 - acc: 0.2482 - val_loss: 1.1093 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.10934, saving model to ./model_180717/CNN/val_loss-1.1093.hdf5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.64583, saving model to ./model_180717/CNN/val_acc-0.6458.hdf5\n",
      "Epoch 2/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 1.2877 - acc: 0.5846 - val_loss: 0.7117 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.10934 to 0.71168, saving model to ./model_180717/CNN/val_loss-0.7117.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.64583 to 0.79167, saving model to ./model_180717/CNN/val_acc-0.7917.hdf5\n",
      "Epoch 3/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.8237 - acc: 0.7224 - val_loss: 0.6409 - val_acc: 0.8021\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.71168 to 0.64087, saving model to ./model_180717/CNN/val_loss-0.6409.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.79167 to 0.80208, saving model to ./model_180717/CNN/val_acc-0.8021.hdf5\n",
      "Epoch 4/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.5295 - acc: 0.8189 - val_loss: 0.5851 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64087 to 0.58507, saving model to ./model_180717/CNN/val_loss-0.5851.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.80208 to 0.82292, saving model to ./model_180717/CNN/val_acc-0.8229.hdf5\n",
      "Epoch 5/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.3674 - acc: 0.8860 - val_loss: 0.5505 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.58507 to 0.55048, saving model to ./model_180717/CNN/val_loss-0.5505.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.82292 to 0.83333, saving model to ./model_180717/CNN/val_acc-0.8333.hdf5\n",
      "Epoch 6/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.2765 - acc: 0.9237 - val_loss: 0.5558 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.55048\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.83333\n",
      "Epoch 7/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.2201 - acc: 0.9522 - val_loss: 0.5258 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.55048 to 0.52575, saving model to ./model_180717/CNN/val_loss-0.5258.hdf5\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.83333\n",
      "Epoch 8/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.1647 - acc: 0.9678 - val_loss: 0.5027 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.52575 to 0.50267, saving model to ./model_180717/CNN/val_loss-0.5027.hdf5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.83333 to 0.83854, saving model to ./model_180717/CNN/val_acc-0.8385.hdf5\n",
      "Epoch 9/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.1382 - acc: 0.9733 - val_loss: 0.5025 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.50267 to 0.50249, saving model to ./model_180717/CNN/val_loss-0.5025.hdf5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.83854 to 0.84375, saving model to ./model_180717/CNN/val_acc-0.8438.hdf5\n",
      "Epoch 10/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.1096 - acc: 0.9853 - val_loss: 0.4879 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.50249 to 0.48788, saving model to ./model_180717/CNN/val_loss-0.4879.hdf5\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.84375\n",
      "Epoch 11/100\n",
      "1088/1088 [==============================] - 17s 15ms/step - loss: 0.0981 - acc: 0.9881 - val_loss: 0.4822 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.48788 to 0.48221, saving model to ./model_180717/CNN/val_loss-0.4822.hdf5\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.84375\n",
      "Epoch 12/100\n",
      "1088/1088 [==============================] - 18s 17ms/step - loss: 0.0763 - acc: 0.9926 - val_loss: 0.4748 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.48221 to 0.47475, saving model to ./model_180717/CNN/val_loss-0.4748.hdf5\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.84375\n",
      "Epoch 13/100\n",
      "1088/1088 [==============================] - 18s 16ms/step - loss: 0.0669 - acc: 0.9945 - val_loss: 0.4688 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.47475 to 0.46880, saving model to ./model_180717/CNN/val_loss-0.4688.hdf5\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.84375 to 0.84896, saving model to ./model_180717/CNN/val_acc-0.8490.hdf5\n",
      "Epoch 14/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0622 - acc: 0.9963 - val_loss: 0.4674 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.46880 to 0.46736, saving model to ./model_180717/CNN/val_loss-0.4674.hdf5\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.84896\n",
      "Epoch 15/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0524 - acc: 0.9963 - val_loss: 0.4602 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.46736 to 0.46021, saving model to ./model_180717/CNN/val_loss-0.4602.hdf5\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.84896\n",
      "Epoch 16/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0575 - acc: 0.9890 - val_loss: 0.4598 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.46021 to 0.45985, saving model to ./model_180717/CNN/val_loss-0.4598.hdf5\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.84896\n",
      "Epoch 17/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0445 - acc: 0.9972 - val_loss: 0.4628 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.45985\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.84896\n",
      "Epoch 18/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0466 - acc: 0.9945 - val_loss: 0.4585 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.45985 to 0.45850, saving model to ./model_180717/CNN/val_loss-0.4585.hdf5\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.84896\n",
      "Epoch 19/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0340 - acc: 0.9954 - val_loss: 0.4597 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.45850\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.84896\n",
      "Epoch 20/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0365 - acc: 0.9963 - val_loss: 0.4582 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.45850 to 0.45824, saving model to ./model_180717/CNN/val_loss-0.4582.hdf5\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.84896\n",
      "Epoch 21/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0357 - acc: 0.9963 - val_loss: 0.4465 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.45824 to 0.44650, saving model to ./model_180717/CNN/val_loss-0.4465.hdf5\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.84896 to 0.85417, saving model to ./model_180717/CNN/val_acc-0.8542.hdf5\n",
      "Epoch 22/100\n",
      "1088/1088 [==============================] - 17s 15ms/step - loss: 0.0293 - acc: 0.9982 - val_loss: 0.4555 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.44650\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.85417\n",
      "Epoch 23/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0290 - acc: 0.9972 - val_loss: 0.4427 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.44650 to 0.44274, saving model to ./model_180717/CNN/val_loss-0.4427.hdf5\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.85417\n",
      "Epoch 24/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.4501 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.44274\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.85417\n",
      "Epoch 25/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0217 - acc: 0.9991 - val_loss: 0.4493 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.44274\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.85417\n",
      "Epoch 26/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0197 - acc: 0.9991 - val_loss: 0.4509 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.44274\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.85417\n",
      "Epoch 27/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0230 - acc: 0.9963 - val_loss: 0.4434 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.44274\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.85417\n",
      "Epoch 28/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0165 - acc: 0.9991 - val_loss: 0.4448 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.44274\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.85417\n",
      "Epoch 29/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0197 - acc: 0.9982 - val_loss: 0.4487 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.44274\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.85417\n",
      "Epoch 30/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0155 - acc: 0.9982 - val_loss: 0.4453 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.44274\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.85417\n",
      "Epoch 31/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0154 - acc: 0.9991 - val_loss: 0.4488 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.44274\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.85417\n",
      "Epoch 32/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0188 - acc: 0.9982 - val_loss: 0.4426 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.44274 to 0.44261, saving model to ./model_180717/CNN/val_loss-0.4426.hdf5\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.85417\n",
      "Epoch 33/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0148 - acc: 0.9982 - val_loss: 0.4512 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.44261\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.85417\n",
      "Epoch 34/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0160 - acc: 0.9991 - val_loss: 0.4444 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.44261\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.85417\n",
      "Epoch 35/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.4446 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.44261\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.85417\n",
      "Epoch 36/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0137 - acc: 0.9991 - val_loss: 0.4474 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.44261\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.85417\n",
      "Epoch 37/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0147 - acc: 0.9972 - val_loss: 0.4429 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.44261\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.85417\n",
      "Epoch 38/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0105 - acc: 0.9982 - val_loss: 0.4402 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.44261 to 0.44024, saving model to ./model_180717/CNN/val_loss-0.4402.hdf5\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.85417\n",
      "Epoch 39/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0160 - acc: 0.9991 - val_loss: 0.4458 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.44024\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.85417 to 0.85938, saving model to ./model_180717/CNN/val_acc-0.8594.hdf5\n",
      "Epoch 40/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4469 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.44024\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.85938\n",
      "Epoch 41/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4437 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.44024\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.85938\n",
      "Epoch 42/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0128 - acc: 0.9991 - val_loss: 0.4426 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.44024\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.85938\n",
      "Epoch 43/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0103 - acc: 0.9991 - val_loss: 0.4553 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.44024\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.85938\n",
      "Epoch 44/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4400 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.44024 to 0.43997, saving model to ./model_180717/CNN/val_loss-0.4400.hdf5\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.85938\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0076 - acc: 0.9991 - val_loss: 0.4424 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.43997\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.85938 to 0.86458, saving model to ./model_180717/CNN/val_acc-0.8646.hdf5\n",
      "Epoch 46/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0087 - acc: 0.9991 - val_loss: 0.4427 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.43997\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.86458\n",
      "Epoch 47/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0082 - acc: 0.9982 - val_loss: 0.4466 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.43997\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.86458\n",
      "Epoch 48/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0161 - acc: 0.9982 - val_loss: 0.4432 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.43997\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.86458\n",
      "Epoch 49/100\n",
      "1088/1088 [==============================] - 15s 14ms/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.4471 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.43997\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.86458\n",
      "Epoch 50/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0078 - acc: 0.9982 - val_loss: 0.4477 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.43997\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.86458\n",
      "Epoch 51/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0199 - acc: 0.9991 - val_loss: 0.4396 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.43997 to 0.43960, saving model to ./model_180717/CNN/val_loss-0.4396.hdf5\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.86458\n",
      "Epoch 52/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0125 - acc: 0.9991 - val_loss: 0.4452 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.43960\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.86458\n",
      "Epoch 53/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.4490 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.43960\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.86458 to 0.86979, saving model to ./model_180717/CNN/val_acc-0.8698.hdf5\n",
      "Epoch 54/100\n",
      "1088/1088 [==============================] - 16s 15ms/step - loss: 0.0083 - acc: 0.9991 - val_loss: 0.4435 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.43960\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.86979\n",
      "Epoch 55/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0140 - acc: 0.9991 - val_loss: 0.4462 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.43960\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.86979\n",
      "Epoch 56/100\n",
      "1088/1088 [==============================] - 15s 14ms/step - loss: 0.0095 - acc: 0.9991 - val_loss: 0.4516 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.43960\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.86979\n",
      "Epoch 57/100\n",
      "1088/1088 [==============================] - 15s 14ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.4471 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.43960\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.86979\n",
      "Epoch 58/100\n",
      "1088/1088 [==============================] - 15s 14ms/step - loss: 0.0186 - acc: 0.9982 - val_loss: 0.4486 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.43960\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.86979\n",
      "Epoch 59/100\n",
      "1088/1088 [==============================] - 15s 14ms/step - loss: 0.0126 - acc: 0.9982 - val_loss: 0.4403 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.43960\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.86979\n",
      "Epoch 60/100\n",
      "1088/1088 [==============================] - 16s 14ms/step - loss: 0.0086 - acc: 0.9991 - val_loss: 0.4420 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.43960\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.86979\n",
      "Epoch 61/100\n",
      "1088/1088 [==============================] - 15s 14ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.4425 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.43960\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.86979\n"
     ]
    }
   ],
   "source": [
    "cnn = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnlstm = CNNLSTMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnngru = CNNGRUModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train(history):\n",
    "    fig, loss_ax = plt.subplots(figsize=(6,6))\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_ylim([0.0, 3.0])\n",
    "\n",
    "    acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "    acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "    acc_ax.set_ylim([0.0, 1.1])\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def test_summary(model, weight_path):\n",
    "    plot_train(model[1])\n",
    "    model[0].load_weights(weight_path)\n",
    "    loss, acc = model[0].evaluate(x_test, y_test, batch_size=batch_size)\n",
    "    print('----- Evaluation loss and metrics -----')\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', acc)\n",
    "    \n",
    "def saveModel(model, name):\n",
    "    model_json = model[0].to_json()\n",
    "    with open(name, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "def loadModel(modelfile, weightfile):\n",
    "    json_file = open(modelfile, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(weightfile)\n",
    "    loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 5ms/step\n",
      "----- Evaluation loss and metrics -----\n",
      "Test loss: 0.5007837802171707\n",
      "Test accuracy: 0.878125\n"
     ]
    }
   ],
   "source": [
    "test_summary(cnn,'./model_180715/CNN/val_loss-0.4396.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveModel(gru, 'gru-0.828.json')\n",
    "#saveModel(lstm, 'lstm-825.json')\n",
    "saveModel(cnn, 'cnn-0.878.json')\n",
    "#saveModel(cnngru, 'cnngru-0.856.json')\n",
    "#saveModel(cnnlstm, 'cnnlstm-0.853.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnbes = loadModel('./cnn-0.878.json','./model_180715/CNN/val_loss-0.4396.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 6ms/step\n",
      "----- Evaluation loss and metrics -----\n",
      "Test loss: 0.5007837802171707\n",
      "Test accuracy: 0.878125\n"
     ]
    }
   ],
   "source": [
    "loss, acc = cnnbes.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('----- Evaluation loss and metrics -----')\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
